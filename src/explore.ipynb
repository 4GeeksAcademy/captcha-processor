{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: ultralytics in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (8.3.80)\n",
                        "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (1.26.4)\n",
                        "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (3.9.4)\n",
                        "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
                        "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (10.2.0)\n",
                        "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (6.0.2)\n",
                        "Requirement already satisfied: requests>=2.23.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (2.32.3)\n",
                        "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (1.13.1)\n",
                        "Requirement already satisfied: torch>=1.8.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (2.6.0)\n",
                        "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (0.21.0)\n",
                        "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (4.67.1)\n",
                        "Requirement already satisfied: psutil in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (5.9.8)\n",
                        "Requirement already satisfied: py-cpuinfo in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (9.0.0)\n",
                        "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (1.5.2)\n",
                        "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (0.13.2)\n",
                        "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (2.0.14)\n",
                        "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
                        "Requirement already satisfied: cycler>=0.10 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
                        "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
                        "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
                        "Requirement already satisfied: packaging>=20.0 in c:\\users\\marina\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
                        "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
                        "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\marina\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
                        "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.5.2)\n",
                        "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
                        "Requirement already satisfied: filelock in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
                        "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\marina\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
                        "Requirement already satisfied: networkx in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
                        "Requirement already satisfied: jinja2 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
                        "Requirement already satisfied: fsspec in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.2.0)\n",
                        "Requirement already satisfied: sympy==1.13.1 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
                        "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
                        "Requirement already satisfied: colorama in c:\\users\\marina\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
                        "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\marina\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.21.0)\n",
                        "Requirement already satisfied: six>=1.5 in c:\\users\\marina\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\marina\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n"
                    ]
                }
            ],
            "source": [
                "'''!pip install ultralytics'''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'!pip install opencv-python'"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''!pip install opencv-python'''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'pip install opendatasets'"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''pip install opendatasets'''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import requests\n",
                "from pickle import dump\n",
                "import os\n",
                "import opendatasets as od\n",
                "import zipfile\n",
                "import tensorflow as tf\n",
                "from keras.preprocessing import image\n",
                "from pathlib import Path\n",
                "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
                "from tensorflow.keras.optimizers import Adam, SGD\n",
                "import keras_tuner as kt\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "import shutil\n",
                "from keras.models import Sequential\n",
                "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, MaxPooling2D\n",
                "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
                "from keras.models import load_model\n",
                "from keras.losses import *\n",
                "from tensorflow.keras import *\n",
                "import random\n",
                "import hashlib\n",
                "import cv2\n",
                "from matplotlib import pyplot as plt\n",
                "import re\n",
                "import ultralytics\n",
                "from IPython.display import clear_output"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First of all, we download the files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'# Assign the Kaggle data set URL into variable\\ndataset = \"https://www.kaggle.com/datasets/youthamj/captchaobjectdetection\"\\n# Using opendatasets let\\'s download the data sets\\nod.download(dataset, data_dir=\"../data/raw/\", force=True)'"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''# Assign the Kaggle data set URL into variable\n",
                "dataset = \"https://www.kaggle.com/datasets/youthamj/captchaobjectdetection\"\n",
                "# Using opendatasets let's download the data sets\n",
                "od.download(dataset, data_dir=\"../data/raw/\", force=True)'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we calculate the number of files donwloaded."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'data_dir = \"../data/raw/captchaobjectdetection\"\\n\\nprint(len([file for file in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, file))]))'"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''data_dir = \"../data/raw/captchaobjectdetection\"\n",
                "\n",
                "print(len([file for file in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, file))]))'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Then, we calculate the number of images (.png extension)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'im_count = 0\\n\\nfor im in Path(data_dir).glob(\"*.png\"):\\n    im_count+=1\\n\\nprint(im_count)'"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''im_count = 0\n",
                "\n",
                "for im in Path(data_dir).glob(\"*.png\"):\n",
                "    im_count+=1\n",
                "\n",
                "print(im_count)'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can observe that the number of images and files differ by one since there are 200,001 files in total and 100,000 images. Therefore, we have one extra file aside from those associated with each image.\n",
                "\n",
                "The extra file is all_sequences.txt, that contains the relationship between the name of the image/file and the characters that contains.\n",
                "\n",
                "We will use this file to asociate the characters in each row to the number asociated to it in the YOLO files."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The content of the files could be duplicated since there could be two different images with the same characters to decipher, so we only check there are no duplicates in our images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'def hashfile(file_path):\\n    hasher = hashlib.sha256()\\n    with open(file_path, \\'rb\\') as f:\\n        buf = f.read()\\n        hasher.update(buf)\\n    return hasher.hexdigest()\\n\\n\\nhashes = pd.DataFrame(columns=[\"filename\",\"hash\"])\\nhashes_dup = pd.DataFrame(columns=[\"filename\",\"hash\"])\\n\\nfor filename in Path(data_dir).glob(\"*.png\"):\\n  if filename.is_file():\\n    file_hash = hashfile(filename)\\n    if (hashes[\"hash\"] != file_hash).all():\\n      hashes.loc[len(hashes)] = [filename, file_hash]\\n    else:\\n      hashes_dup.loc[len(hashes_dup)] = [filename, file_hash]\\n\\nif hashes_dup.empty:\\n  print(\"No duplicates in the dataset.\")\\nelse:\\n    print(hashes_dup)'"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''def hashfile(file_path):\n",
                "    hasher = hashlib.sha256()\n",
                "    with open(file_path, 'rb') as f:\n",
                "        buf = f.read()\n",
                "        hasher.update(buf)\n",
                "    return hasher.hexdigest()\n",
                "\n",
                "\n",
                "hashes = pd.DataFrame(columns=[\"filename\",\"hash\"])\n",
                "hashes_dup = pd.DataFrame(columns=[\"filename\",\"hash\"])\n",
                "\n",
                "for filename in Path(data_dir).glob(\"*.png\"):\n",
                "  if filename.is_file():\n",
                "    file_hash = hashfile(filename)\n",
                "    if (hashes[\"hash\"] != file_hash).all():\n",
                "      hashes.loc[len(hashes)] = [filename, file_hash]\n",
                "    else:\n",
                "      hashes_dup.loc[len(hashes_dup)] = [filename, file_hash]\n",
                "\n",
                "if hashes_dup.empty:\n",
                "  print(\"No duplicates in the dataset.\")\n",
                "else:\n",
                "    print(hashes_dup)'''\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's check then an inmage, and it's bounding boxes, to see everything goes as expected in the YOLO files."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we check as an example a random image and its bounding box, to check the values are defined as expected."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_img(img_dir, txt_dir):\n",
                "    image = cv2.imread(img_dir)\n",
                "    image_hight = image.shape[0]\n",
                "    image_width = image.shape[1]\n",
                "\n",
                "    filename = txt_dir\n",
                "\n",
                "    with open(filename, 'r', encoding='utf-8') as f:\n",
                "        text_list = [list(map(float, line.strip().split())) for line in f]\n",
                "\n",
                "\n",
                "    for i in range(len(text_list)):\n",
                "        x0 = text_list[i][1] - text_list[1][3] / 2\n",
                "        x1 = text_list[i][1] + text_list[i][3] / 2\n",
                "        y0 = text_list[i][2] - text_list[i][4] / 2\n",
                "        y1 = text_list[i][2] + text_list[i][4] / 2\n",
                "\n",
                "        start_point = (int(x0*image_width), int(y0*image_hight))\n",
                "        end_point = (int(x1*image_width), int(y1*image_hight))\n",
                "\n",
                "        img = cv2.rectangle(image, start_point, end_point, color=(255, 0, 0), thickness=2)\n",
                "\n",
                "    plt.imshow(img)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'img_dir = \"../data/raw/images/train/10084.png\"\\n\\ntxt_dir = \"../data/raw/labels/train/10084.txt\"\\n\\nplot_img(img_dir, txt_dir)\\n'"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''img_dir = \"../data/raw/images/train/10084.png\"\n",
                "\n",
                "txt_dir = \"../data/raw/labels/train/10084.txt\"\n",
                "\n",
                "plot_img(img_dir, txt_dir)\n",
                "'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Finally, it's time to create the folders to divide the files in txt and images, and then split then in 3 subsets of train, validation and test, in a rate of 60-20-20."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'os.makedirs(\"../data/raw/images\")\\nos.makedirs(\"../data/raw/labels\")'"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''os.makedirs(\"../data/raw/images\")\n",
                "os.makedirs(\"../data/raw/labels\")'''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'for im in Path(\"data_dir\").glob(\"*.png\"):\\n    shutil.move(im, os.path.join(\"../data/raw/images\", im.name))\\n\\nfor im in Path(\"data_dir\").glob(\"*.txt\"):\\n    shutil.move(im, os.path.join(\"../data/raw/labels\", im.name))\\n\\nfor im in Path(\"../data/raw/labels\").glob(\"all_sequences.txt\"):\\n    shutil.move(im, os.path.join(\"data_dir\", im.name))'"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''for im in Path(\"data_dir\").glob(\"*.png\"):\n",
                "    shutil.move(im, os.path.join(\"../data/raw/images\", im.name))\n",
                "\n",
                "for im in Path(\"data_dir\").glob(\"*.txt\"):\n",
                "    shutil.move(im, os.path.join(\"../data/raw/labels\", im.name))\n",
                "\n",
                "for im in Path(\"../data/raw/labels\").glob(\"all_sequences.txt\"):\n",
                "    shutil.move(im, os.path.join(\"data_dir\", im.name))'''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'os.makedirs(\"../data/raw/images/train\")\\nos.makedirs(\"../data/raw/images/val\")\\nos.makedirs(\"../data/raw/images/test\")'"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''os.makedirs(\"../data/raw/images/train\")\n",
                "os.makedirs(\"../data/raw/images/val\")\n",
                "os.makedirs(\"../data/raw/images/test\")'''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'os.makedirs(\"../data/raw/labels/train\")\\nos.makedirs(\"../data/raw/labels/val\")\\nos.makedirs(\"../data/raw/labels/test\")'"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''os.makedirs(\"../data/raw/labels/train\")\n",
                "os.makedirs(\"../data/raw/labels/val\")\n",
                "os.makedirs(\"../data/raw/labels/test\")'''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'origin = \"../data/raw/images\"\\ndestiny_train = \"../data/raw/images/train\"\\ndestiny_val = \"../data/raw/images/val\"\\ndestiny_test = \"../data/raw/images/test\"\\n\\nfiles = [f for f in os.listdir(origin) if os.path.isfile(os.path.join(origin, f))]\\n    \\nsize_to_move = int(len(files) * (20 / 100))\\n    \\nfiles_to_move_val = random.sample(files, size_to_move)\\n\\nfor file in files_to_move_val:\\n    shutil.move(os.path.join(origin, file), os.path.join(destiny_val, file))\\n\\nfiles = [f for f in os.listdir(origin) if os.path.isfile(os.path.join(origin, f))]\\nfiles_to_move_test = random.sample(files, size_to_move)\\n\\nfor file in files_to_move_test:\\n    shutil.move(os.path.join(origin, file), os.path.join(destiny_test, file))\\n\\nfor im in Path(\"../data/raw/images\").glob(\"*.png\"):\\n    shutil.move(im, os.path.join(\"../data/raw/images/train\", im.name))'"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''origin = \"../data/raw/images\"\n",
                "destiny_train = \"../data/raw/images/train\"\n",
                "destiny_val = \"../data/raw/images/val\"\n",
                "destiny_test = \"../data/raw/images/test\"\n",
                "\n",
                "files = [f for f in os.listdir(origin) if os.path.isfile(os.path.join(origin, f))]\n",
                "    \n",
                "size_to_move = int(len(files) * (20 / 100))\n",
                "    \n",
                "files_to_move_val = random.sample(files, size_to_move)\n",
                "\n",
                "for file in files_to_move_val:\n",
                "    shutil.move(os.path.join(origin, file), os.path.join(destiny_val, file))\n",
                "\n",
                "files = [f for f in os.listdir(origin) if os.path.isfile(os.path.join(origin, f))]\n",
                "files_to_move_test = random.sample(files, size_to_move)\n",
                "\n",
                "for file in files_to_move_test:\n",
                "    shutil.move(os.path.join(origin, file), os.path.join(destiny_test, file))\n",
                "\n",
                "for im in Path(\"../data/raw/images\").glob(\"*.png\"):\n",
                "    shutil.move(im, os.path.join(\"../data/raw/images/train\", im.name))'''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'destiny_train_im = \"../data/raw/images/train\"\\ndestiny_val_im = \"../data/raw/images/val\"\\ndestiny_test_im = \"../data/raw/images/test\"\\n\\norigin_txt = \"../data/raw/labels\"\\ndestiny_train_txt = \"../data/raw/labels/train\"\\ndestiny_val_txt = \"../data/raw/labels/val\"\\ndestiny_test_txt = \"../data/raw/labels/test\"\\n\\nim_train = {os.path.splitext(f)[0] for f in os.listdir(destiny_train_im) if os.path.isfile(os.path.join(destiny_train_im, f))}\\nim_val = {os.path.splitext(f)[0] for f in os.listdir(destiny_val_im) if os.path.isfile(os.path.join(destiny_val_im, f))}\\nim_test = {os.path.splitext(f)[0] for f in os.listdir(destiny_test_im) if os.path.isfile(os.path.join(destiny_test_im, f))}\\n\\nfor file in os.listdir(origin_txt):\\n    path = os.path.join(origin_txt, file)\\n\\n    if os.path.isfile(path):\\n        root, _ = os.path.splitext(file)\\n\\n        # Si el nombre coincide con los nombres de la carpeta de imágenes, moverlo\\n        if root in im_train:\\n            shutil.move(path, os.path.join(destiny_train_txt, file))\\n        \\n        elif root in im_val:\\n            shutil.move(path, os.path.join(destiny_val_txt, file))\\n\\n        elif root in im_test:\\n            shutil.move(path, os.path.join(destiny_test_txt, file))'"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''destiny_train_im = \"../data/raw/images/train\"\n",
                "destiny_val_im = \"../data/raw/images/val\"\n",
                "destiny_test_im = \"../data/raw/images/test\"\n",
                "\n",
                "origin_txt = \"../data/raw/labels\"\n",
                "destiny_train_txt = \"../data/raw/labels/train\"\n",
                "destiny_val_txt = \"../data/raw/labels/val\"\n",
                "destiny_test_txt = \"../data/raw/labels/test\"\n",
                "\n",
                "im_train = {os.path.splitext(f)[0] for f in os.listdir(destiny_train_im) if os.path.isfile(os.path.join(destiny_train_im, f))}\n",
                "im_val = {os.path.splitext(f)[0] for f in os.listdir(destiny_val_im) if os.path.isfile(os.path.join(destiny_val_im, f))}\n",
                "im_test = {os.path.splitext(f)[0] for f in os.listdir(destiny_test_im) if os.path.isfile(os.path.join(destiny_test_im, f))}\n",
                "\n",
                "for file in os.listdir(origin_txt):\n",
                "    path = os.path.join(origin_txt, file)\n",
                "\n",
                "    if os.path.isfile(path):\n",
                "        root, _ = os.path.splitext(file)\n",
                "\n",
                "        # Si el nombre coincide con los nombres de la carpeta de imágenes, moverlo\n",
                "        if root in im_train:\n",
                "            shutil.move(path, os.path.join(destiny_train_txt, file))\n",
                "        \n",
                "        elif root in im_val:\n",
                "            shutil.move(path, os.path.join(destiny_val_txt, file))\n",
                "\n",
                "        elif root in im_test:\n",
                "            shutil.move(path, os.path.join(destiny_test_txt, file))'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's check the folders have the number of files expected."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'print(len(os.listdir(destiny_train_im)))\\nprint(len(os.listdir(destiny_val_im)))\\nprint(len(os.listdir(destiny_test_im)))\\n\\nprint(len(os.listdir(destiny_train_txt)))\\nprint(len(os.listdir(destiny_val_txt)))\\nprint(len(os.listdir(destiny_test_txt)))'"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''print(len(os.listdir(destiny_train_im)))\n",
                "print(len(os.listdir(destiny_val_im)))\n",
                "print(len(os.listdir(destiny_test_im)))\n",
                "\n",
                "print(len(os.listdir(destiny_train_txt)))\n",
                "print(len(os.listdir(destiny_val_txt)))\n",
                "print(len(os.listdir(destiny_test_txt)))'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Meanwhile, we've been analyzing the file all_sequences.txt, with the characters associated to each image, and compare them with every txt file associated to each image, to obtain the YOLO yaml index associated to each character.\n",
                "\n",
                "We noticed that there are some characters missing, so we check this characters don't exist in any file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'filename = \"../data/raw/captchaobjectdetection/all_sequences.txt\"\\n\\nwith open(filename, \\'r\\', encoding=\\'utf-8\\') as f:\\n  char_list = [linea.strip().split(\",\") for linea in f]\\n\\ndata = []\\nfor item in char_list:\\n   if re.search(r\"iIlLoO01\", item[1]):\\n    data.append(item)\\n\\nprint(data)'"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''filename = \"../data/raw/captchaobjectdetection/all_sequences.txt\"\n",
                "\n",
                "with open(filename, 'r', encoding='utf-8') as f:\n",
                "  char_list = [linea.strip().split(\",\") for linea in f]\n",
                "\n",
                "data = []\n",
                "for item in char_list:\n",
                "   if re.search(r\"iIlLoO01\", item[1]):\n",
                "    data.append(item)\n",
                "\n",
                "print(data)'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's begin with the YOLO model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ultralytics import YOLO\n",
                "model = YOLO(\"yolov8n.pt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "img_dir = \"../data/raw/images/train/3.png\"\n",
                "image = cv2.imread(img_dir)\n",
                "image_size = image.size"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First of all, we train the model with our dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'results = model.train(\\n    data=\"./dataset.yaml\",  # Ruta al archivo de configuración del dataset\\n    epochs=50,  # Número de épocas de entrenamiento\\n    imgsz=image_size,  # Tamaño de las imágenes\\n    batch=16  # Tamaño del batch\\n)'"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''results = model.train(\n",
                "    data=\"./dataset.yaml\",  # Ruta al archivo de configuración del dataset\n",
                "    epochs=50,  # Número de épocas de entrenamiento\n",
                "    imgsz=image_size,  # Tamaño de las imágenes\n",
                "    batch=16  # Tamaño del batch\n",
                ")'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "When we try to train the model, we can see the following error:\n",
                "\n",
                "val: WARNING  C:\\4Geeks\\Projects\\captcha-processor\\data\\raw\\images\\val\\9998.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333]\n",
                "train: WARNING  C:\\4Geeks\\Projects\\captcha-processor\\data\\raw\\images\\train\\99960.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333]\n",
                "\n",
                "It seems that thousands of the YOLO files have at least, one value bigger than 1, wich is not valid, due to value normalization.\n",
                "\n",
                "Let's copy some of this images and txt in the original folder, soy we can see whats happenning, and what can we do."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'img_dir = \"../data/interim/10193.png\"\\ntxt_dir = \"../data/interim/10193.txt\"\\n\\nplot_img(img_dir, txt_dir)'"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''img_dir = \"../data/interim/10193.png\"\n",
                "txt_dir = \"../data/interim/10193.txt\"\n",
                "\n",
                "plot_img(img_dir, txt_dir)'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's compare the results whith the YOLO file normalized (replacing any value bigger than one, with one)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'img_dir = \"../data/interim/10193.png\"\\ntxt_dir = \"../data/interim/10193_normalized.txt\"\\n\\nplot_img(img_dir, txt_dir)'"
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''img_dir = \"../data/interim/10193.png\"\n",
                "txt_dir = \"../data/interim/10193_normalized.txt\"\n",
                "\n",
                "plot_img(img_dir, txt_dir)'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can notice that the rectangles stay the same, but the values are now valid in YOLO files, so they have no values outside 0 to 1."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "So, the key now is to replace every value bigger with one, to one, in every text file all along the YOLO files."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First of all in this step is to create a back up of the original txt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'shutil.copytree(\"../data/raw/labels/\", \"../data/raw/captchaobjectdetection\", dirs_exist_ok=True)'"
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''shutil.copytree(\"../data/raw/labels/\", \"../data/raw/captchaobjectdetection\", dirs_exist_ok=True)'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And then, modify the files to normalize values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'dir = \"../data/raw/labels\"\\n\\nfor file in Path(dir).rglob(\"*.txt\"):   \\n    with open(file, \"r+\", encoding=\"utf-8\") as f:\\n        lines = f.readlines()\\n        f.seek(0)  \\n        for line in lines:\\n            values = list(map(float, line.strip().split()))\\n            values = [1 if x > 1 else x for x in values]\\n            f.write(\" \".join(map(str, values)) + \"\\n\")\\n        f.truncate() '"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "'''dir = \"../data/raw/labels\"\n",
                "\n",
                "for file in Path(dir).rglob(\"*.txt\"):   \n",
                "    with open(file, \"r+\", encoding=\"utf-8\") as f:\n",
                "        lines = f.readlines()\n",
                "        f.seek(0)  \n",
                "        for line in lines:\n",
                "            values = list(map(float, line.strip().split()))\n",
                "            values = [1 if x > 1 else x for x in values]\n",
                "            f.write(\" \".join(map(str, values)) + \"\\n\")\n",
                "        f.truncate() '''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's try again the YOLO training, in order to see if our changes normalizing the txt file values have solved the problem."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "New https://pypi.org/project/ultralytics/8.3.81 available  Update with 'pip install -U ultralytics'\n",
                        "Ultralytics 8.3.80  Python-3.9.13 torch-2.6.0+cpu CPU (Intel Core(TM) i7-4750HQ 2.00GHz)\n",
                        "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=./dataset.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=28800, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train11\n",
                        "Overriding model.yaml nc=80 with nc=54\n",
                        "\n",
                        "                   from  n    params  module                                       arguments                     \n",
                        "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
                        "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
                        "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
                        "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
                        "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
                        "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
                        "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
                        "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
                        "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
                        "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
                        " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
                        " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
                        " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
                        " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
                        " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
                        " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
                        " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
                        " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
                        " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
                        " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
                        " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
                        " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
                        " 22        [15, 18, 21]  1    761842  ultralytics.nn.modules.head.Detect           [54, [64, 128, 256]]          \n",
                        "Model summary: 129 layers, 3,021,378 parameters, 3,021,362 gradients, 8.3 GFLOPs\n",
                        "\n",
                        "Transferred 319/355 items from pretrained weights\n",
                        "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train11', view at http://localhost:6006/\n",
                        "Freezing layer 'model.22.dfl.conv.weight'\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\4Geeks\\Projects\\captcha-processor\\data\\raw\\labels\\train.cache... 60000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 60000/60000 [00:00<?, ?it/s]\n",
                        "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\4Geeks\\Projects\\captcha-processor\\data\\raw\\labels\\val.cache... 20000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 20000/20000 [00:00<?, ?it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "module 'matplotlib' has no attribute 'backends'\n",
                        "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
                        "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n"
                    ]
                }
            ],
            "source": [
                "'''results = model.train(\n",
                "    data=\"./dataset.yaml\",  # Ruta al archivo de configuración del dataset\n",
                "    epochs=50,  # Número de épocas de entrenamiento\n",
                "    imgsz=image_size,  # Tamaño de las imágenes\n",
                "    batch=16  # Tamaño del batch\n",
                ")\n",
                "'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Then, we validate it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "'''results = model.val()'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And finally, save the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "'''model.export(format=\"../models/captcha_yolo8_b16_e50\") '''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "'''model = YOLO(\"runs/train/exp/weights/best.pt\")  # Cargar el mejor modelo entrenado\n",
                "\n",
                "# Realizar predicción en una imagen\n",
                "results = model(\"imagen_de_prueba.jpg\")\n",
                "\n",
                "# Mostrar resultados\n",
                "results.show()'''"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
